@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@inproceedings{yosinski-2015-ICML-DL-understanding-neural-networks,
    Author = {Jason Yosinski and Jeff Clune and Anh Nguyen and Thomas Fuchs and Hod Lipson},
    Booktitle = {Deep Learning Workshop, International Conference on Machine Learning (ICML)},
    Title = {Understanding Neural Networks Through Deep Visualization},
Year = {2015}
}

@misc{YoshuaBengioQuoraWhy-did-it-take-so-long ,
    title = {Yoshua Bengio's answer on Quora},
    howpublished = {\url{https://www.quora.com/Why-did-it-take-so-long-to-invent-the-backpropagation-algorithm-Isnt-it-just-a-straightforward-albeit-cumbersome-application-of-the-chain-rule/answer/Yoshua-Bengio?srid=vNI2}},
    note = {Accessed: 2017-04-15}
}

@book{Machine-Learning-Tom-Mitchell-1997,
    title={Machine Learning},
    author={Tom Mitchell, McGraw Hill},
    publisher={McGraw-Hill Education},
    year={1997}
}


@article{Sietsma-Dow,
    author={Jocelyn Sietsma, Robert J. F. Dow},
    title={Creating artificial neural networks that generalize},
    journal={ACM},
    volume={4},
    year=1991,
    pages={67-79}
}

@article{autoencoders-Poole,
    author={Ben Poole, Jascha Sohl-Dickstein, Surya Ganguli},
    title={Analyzing noise in autoencoders and deep networks},
    archivePrefix = "arXiv",
    eprint = {1406.1831},
    primaryClass = "cs.NE",
    year=1991
}

@article{Breiman1996,
    author="Breiman, Leo",
    title="Bagging Predictors",
    journal="Machine Learning",
    year="1996",
    volume="24",
    number="2",
    pages="123--140",
    abstract="Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.",
    issn="1573-0565",
    doi="10.1023/A:1018054314350",
    url="http://dx.doi.org/10.1023/A:1018054314350"
}

@article{5197422, 
    author={Y. Koren and R. Bell and C. Volinsky}, 
    journal={Computer}, 
    title={Matrix Factorization Techniques for Recommender Systems}, 
    year={2009}, 
    volume={42}, 
    number={8}, 
    pages={30-37}, 
    keywords={information filtering;matrix decomposition;retail data processing;Netflix Prize competition;matrix factorization technique;nearest neighbor technique;product recommendation system;recommender system;Bioinformatics;Collaboration;Filtering;Genomics;Motion pictures;Nearest neighbor searches;Predictive models;Recommender systems;Sea measurements;Computational intelligence;Matrix factorization;Netflix Prize}, 
    doi={10.1109/MC.2009.263}, 
    ISSN={0018-9162}, 
    month={Aug}
}

@article{Kelley-1960,
    author={Kelley, Henry J.},
    title={Gradient Theory of Optimal Flight Paths},
    journal={ARS Journal},
    volume={30},
    year=1960
}

@article{Cai:2016:MND:2895845.2896008,
    author = {Cai, Meng and Liu, Jia},
    title = {Maxout Neurons for Deep Convolutional and LSTM Neural Networks in Speech Recognition},
    journal = {Speech Commun.},
    issue_date = {March 2016},
    volume = {77},
    number = {C},
    month = mar,
    year = {2016},
    issn = {0167-6393},
    pages = {53--64},
    numpages = {12},
    url = {http://dx.doi.org/10.1016/j.specom.2015.12.003},
    doi = {10.1016/j.specom.2015.12.003},
    acmid = {2896008},
    publisher = {Elsevier Science Publishers B. V.},
    address = {Amsterdam, The Netherlands, The Netherlands},
    keywords = {Acoustic modeling, Convolutional neural network, Long short-term memory, Maxout neuron, Speech recognition},
} 


@article{Hornik1989359,
    title = "Multilayer feedforward networks are universal approximators ",
    journal = "Neural Networks ",
    volume = "2",
    number = "5",
    pages = "359 - 366",
    year = "1989",
    note = "",
    issn = "0893-6080",
    doi = "https://doi.org/10.1016/0893-6080(89)90020-8",
    url = "http://www.sciencedirect.com/science/article/pii/0893608089900208",
    author = "Kurt Hornik and Maxwell Stinchcombe and Halbert White",
    keywords = "Feedforward networks",
    keywords = "Universal approximation",
    keywords = "Mapping networks",
    keywords = "Network representation capability",
    keywords = "Stone-Weierstrass Theorem",
    keywords = "Squashing functions",
    keywords = "Sigma-Pi networks",
    keywords = "Back-propagation networks "
}

@misc{daggerfs,
    title = {Yangqing Jia's Website},
    howpublished = {\url{http://daggerfs.com/}},
    note = {Accessed: 2017-04-15}
}

@misc{caffe-berkeleyvision,
    title = {Caffe},
    howpublished = {\url{http://caffe.berkeleyvision.org/}},
    note = {Accessed: 2017-04-15}
}


